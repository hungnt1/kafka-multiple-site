---

javaVersion: 8
updateJava: false                                               # only when you need to update java version



useSystemFirewall: true

kafkaGroup: kafka
kafkaUser: kafka
kafkaGroupId: 7000
kafkaUserId: 7000

kafkaInstallDir: /kafka
kafkaDataDir: "{{ kafkaInstallDir }}/kafka-data"
kafkaLogDir: "{{ kafkaInstallDir }}/kafka-logs"

# JVM Settings
# total memory * 0.25 or 25% or total memory only
# Rest 75% will be used for Caching 
kafkaXms: 6G                                                    # 6GB is max recommended for production kafka
kafkaXmx: "{{ kafkaXms }}"
kafkaPort: 9093
kafkaSecure: 9093
secure: true
kafkaJmxPort: 9999
kafkaVmMaxMapCount: 100000

# zookeeper string should comma separate value
# 192.168.56.100:2181,192.168.56.101:2181,192.168.56.102:2181
kafkaZookeeperAddressString: zookeeper01.site2:2182
kafkaZookeeperConnectionTimeoutMs: 10000

# please use name like <environment>-kafka, so it get distinct name in NewRelic
kafkaClusterName: development-kafka

kafkaVersion: 2.8.0
kafkaScalaVersion: 2.12
kafkaTarLocation: "/home/hungnt1/kafka_{{ kafkaScalaVersion }}-{{ kafkaVersion }}.tgz"

# below will be used while decommission/downgrade only
kafkaOldVersion: 2.2.0
kafkaOldScalaVersion: 2.12

### Production Optimization Parameters
### if nothing is set then it will use default values.
kafkaDefaultReplicationFactor: 2
kafkaMinInsyncReplicas: "{{ kafkaDefaultReplicationFactor | int - 1 }}"
kafkaBackgroundThread: 10
kafkaMessagesMaxBytes: 1000012                                    # 1MB approx
kafkaReplicaFetchMaxBytes: 2000000                                # this should be higher than kafkaMessagesMaxBytes
kafkaQuededMaxRequests: 500
kafkaNumReplicaFetchers: 1
kafkaNumNetworkThreads: 6
kafkaNumIoThreads: 8
kafkaSocketSendBufferBytes: 102400
kafkaSocetReceiveBufferBytes: 102400
kafkaSocetRequestMaxBytes: 104857600
kafkaNumPartitions: 1
kafkaNumRecoveryThreadsPerDataDir: 1
kafkaOffsetsTopicReplicationFactor: 2
kafkaTransactionStateLogReplicationFactor: "{{ kafkaOffsetsTopicReplicationFactor}}"
kafkaTransactionStateLogMinIsr: "{{  kafkaOffsetsTopicReplicationFactor }}"
kafkaLogFlushIntervalMessages: 10000
kafkaLogFlushIntervalMs: 1000
kafkaLogRetentionHours: 168
kafkaLogSegmentBytes: 2073741824                                # need to ask expert kafka, should we use default 1GB here or 2GB or more
kafkalogRetentionCheckIntervalMs: 300000
kafkaGroupInitRebalanceDelayMs: 3



## Secure 
secure: true
ssl_public_ca_dir: "/usr/local/kafka/exchange/ssl-ca-public"
ssl_exchange: "/usr/local/kafka/exchange/ssl-exchange"
ssl_public_client_dir: "/usr/local/kafka/exchange/ssl-client-dir-public"
keystore_pwd: keystore-secretanh99em2400379-public
key_pwd: "{{ keystore_pwd }}"
truststore_pwd: truststore-secretanh99em2400379-public
# DNSname: "DNS:zookeeper01.site2,DNS:zookeeper02.site2,DNS:zookeeper02.site2"
DNSnamePublic: "DNS:kafka.message.iview.vn,DNS:kafka01.site2,DNS:kafka02.site2,DNS:kafka03.site2"
ca_pwd: ca-secretanh99em2400379

# zookeeper

keystore_pwd_zk: keystore-secretanh99em2400379
truststore_pwd_zk: truststore-secretanh99em2400379

## client 

ssl_broker_dir: "/usr/local/kafka/exchange/ssl-broker-dir"

ssl_box_client_dir: "/usr/local/kafka/exchange/ssl-client-box-dir"

# Only for AWS Based Cluster
aws_kafka_ec2_region: "eu-central-1"
aws_kafka_ebs_device: "/dev/xvdc"
aws_kafka_ebs_device_fs: "xfs"                                # currently tested with xfs only.
aws_kafka_ebs_device_mount_location: "{{ kafkaInstallDir }}"